{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit Distance for Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T02:52:02.226006200Z",
     "start_time": "2024-09-20T02:52:02.121697700Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: isi nama dan NPM Anda\n",
    "\n",
    "nama = 'Mohamad Arvin Fadriansyah'\n",
    "npm = '2106708311'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T02:52:02.294061400Z",
     "start_time": "2024-09-20T02:52:02.144732200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import library yang diperlukan\n",
    "import random\n",
    "\n",
    "from utils import load_json, format_report\n",
    "from trie_structure.levenshtein_trie import LevenshteinTrie\n",
    "from trie_structure.damerau_levenshtein_trie import DamerauLevenshteinTrie\n",
    "from dict_structure.levenshtein_dict import LevenshteinDict\n",
    "from dict_structure.damerau_levenshtein_dict import DamerauLevenshteinDict\n",
    "from performance import Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T02:52:02.295056900Z",
     "start_time": "2024-09-20T02:52:02.264576400Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Definisikan path dari dataset KBBI dan non word error (typo)\n",
    "\n",
    "KBBI_PATH = 'bahasa-indonesia-dictionary.txt'\n",
    "TYPO_PATH = 'saltik.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T02:52:02.414377900Z",
     "start_time": "2024-09-20T02:52:02.283523600Z"
    }
   },
   "outputs": [],
   "source": [
    "typo_dataset = load_json(TYPO_PATH)\n",
    "\n",
    "# random sampling berdasarkan NPM\n",
    "random.seed(int(npm))\n",
    "sample_size = 5\n",
    "typo_sample_keys = random.sample(list(typo_dataset.keys()), sample_size)\n",
    "typo_sample_dataset = {key: typo_dataset[key] for key in typo_sample_keys}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Algoritma Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T02:52:05.954465200Z",
     "start_time": "2024-09-20T02:52:02.407369400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trie\n",
    "lev_trie = LevenshteinTrie(dict_path=KBBI_PATH)\n",
    "dalev_trie = DamerauLevenshteinTrie(dict_path=KBBI_PATH)\n",
    "\n",
    "# Dictionary\n",
    "lev_dict = LevenshteinDict(dict_path=KBBI_PATH)\n",
    "dalev_dict = DamerauLevenshteinDict(dict_path=KBBI_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Performa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T02:52:05.955464400Z",
     "start_time": "2024-09-20T02:52:05.939429100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['garis', ['uaris', 'tyaris', 'rtgaris', 'agis', 'yris', 'qgris', 'tris', 'gis', 'yaris', 'qagris', 'gtaris', 'argis', 'tgris', 'rgis', 'ayris', 'gris', 'tgais', 'rgaris', 'agris', 'tgaris']], ['karyawan', ['qakryawan', 'uiaryawan', 'iryawan', 'uikaryawan', 'arkyawan', 'ikaryawan', 'qryawan', 'uaryawan', 'aryawan', 'kryawan', 'ikryawan', 'qkryawan', 'kiaryawan', 'rayawan', 'iaryawan', 'akryawan', 'qaryawan', 'ukaryawan', 'airyawan', 'ryawan']], ['evolusi', ['qwvolusi', 'fvolusi', 'olusi', 'wvolusi', 'volusi', 'veolusi', 'eolusi', 'vwolusi', 'voelusi', 'qvolusi', 'wolusi', 'fveolusi', 'feolusi', 'weolusi', 'wevolusi', 'qevolusi', 'folusi', 'qwevolusi', 'ovlusi', 'ewvolusi']], ['ibadah', ['uadah', 'uibadah', 'iadah', 'iubadah', 'yubadah', 'biadah', 'abdah', 'giadah', 'buadah', 'hadah', 'bdah', 'gbiadah', 'yuibadah', 'badah', 'uiadah', 'baidah', 'ybadah', 'yibadah', 'gbadah', 'ubadah']], ['departemen', ['epartemen', 'eeartemen', 'wpartemen', 'deepartemen', 'edepartemen', 'wedepartemen', 'wedpartemen', 'wepartemen', 'dpartemen', 'wdepartemen', 'repartemen', 'wdpartemen', 'edeartemen', 'peartemen', 'weepartemen', 'eepartemen', 'epdartemen', 'edpartemen', 'epeartemen', 'partemen']]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ubah Data dari awalnya dictionary menjadi bentuk list 2 dimensi \n",
    "yang tiap row nya mengandung typo sample keys dan list kemungkinan non words error nya \n",
    "\"\"\"\n",
    "typo_sample_dataset_modified = []\n",
    "for key, typo_list in typo_sample_dataset.items():\n",
    "    typos=[]\n",
    "    for typo_data in typo_list:\n",
    "        typos.append(typo_data['typo'])\n",
    "    typo_sample_dataset_modified.append([key,typos])\n",
    "typo_sample_dataset = typo_sample_dataset_modified\n",
    "print(typo_sample_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T02:52:05.989180400Z",
     "start_time": "2024-09-20T02:52:05.955464400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Masukkan tiap model dan typo_sample_dataset ke performance\n",
    "performance_of_lev_trie = Performance(lev_trie, typo_sample_dataset)\n",
    "performance_of_dalev_trie = Performance(dalev_trie, typo_sample_dataset)\n",
    "performance_of_lev_dict = Performance(lev_dict, typo_sample_dataset)\n",
    "performance_of_dalev_dict = Performance(dalev_dict, typo_sample_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T02:52:22.504759600Z",
     "start_time": "2024-09-20T02:52:05.972149500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary untuk formatting\n",
    "performances = {\"lev_trie\": performance_of_lev_trie.calculate_performance(),\n",
    "                \"dalev_trie\": performance_of_dalev_trie.calculate_performance(),\n",
    "                \"lev_dict\": performance_of_lev_dict.calculate_performance(),\n",
    "                \"dalev_dict\" :performance_of_dalev_dict.calculate_performance() \n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T02:52:22.571942800Z",
     "start_time": "2024-09-20T02:52:22.509295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mohamad Arvin Fadriansyah - 2106708311\n",
      "---------- lev_trie ----------\n",
      "Best Accuracy: 0.42\n",
      "Candidate Accuracy: 0.99\n",
      "Time: 8.76181435585022 seconds\n",
      "---------- dalev_trie ----------\n",
      "Best Accuracy: 0.43\n",
      "Candidate Accuracy: 0.99\n",
      "Time: 11.338266849517822 seconds\n",
      "---------- lev_dict ----------\n",
      "Best Accuracy: 0.42\n",
      "Candidate Accuracy: 0.99\n",
      "Time: 10.866144180297852 seconds\n",
      "---------- dalev_dict ----------\n",
      "Best Accuracy: 0.43\n",
      "Candidate Accuracy: 0.99\n",
      "Time: 120.18550753593445 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_report(nama, npm,performances))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
